{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GitHub Repository Data Collector\n",
    "\n",
    "This notebook collects GitHub repository statistics and saves them to a CSV file.\n",
    "\n",
    "## Setup\n",
    "1. Create a `.env` file with your GitHub token: `GITHUB_TOKEN=your_token_here`\n",
    "2. Run all cells to collect fresh data\n",
    "3. Use `github_stats_viewer.ipynb` to view the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"GitHub token available: {'Yes' if os.environ.get('GITHUB_TOKEN') else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repository list with categories\n",
    "repositories = {\n",
    "    \"AI/ML\": [\n",
    "        \"huggingface/trl\",\n",
    "        \"Significant-Gravitas/AutoGPT\",\n",
    "        \"open-webui/open-webui\",\n",
    "        \"comfyanonymous/ComfyUI\",\n",
    "        \"langchain-ai/langchain\",\n",
    "        \"huggingface/transformers\",\n",
    "        \"ollama/ollama\",\n",
    "        \"vllm-project/vllm\",\n",
    "        \"n8n-io/n8n\",\n",
    "        \"iterative/dvc\",\n",
    "        \"langgenius/dify\",\n",
    "        \"HumanSignal/label-studio\",\n",
    "        \"microsoft/ML-For-Beginners\",\n",
    "        \"cleanlab/cleanlab\",\n",
    "        \"voxel51/fiftyone\",\n",
    "        \"fastai/fastbook\",\n",
    "        \"pytorch/pytorch\",\n",
    "        \"tensorflow/tensorflow\",\n",
    "        \"scikit-learn/scikit-learn\",\n",
    "        \"pandas-dev/pandas\"\n",
    "    ],\n",
    "    \"TypeScript\": [\n",
    "        \"nestjs/nest\",\n",
    "        \"prisma/prisma\",\n",
    "        \"adonisjs/core\",\n",
    "        \"typeorm/typeorm\",\n",
    "        \"sequelize/sequelize\",\n",
    "        \"trpc/trpc\",\n",
    "        \"fastify/fastify\",\n",
    "        \"taskforcesh/bullmq\",\n",
    "        \"mikro-orm/mikro-orm\",\n",
    "        \"drizzle-team/drizzle-orm\",\n",
    "        \"kysely-org/kysely\",\n",
    "        \"colinhacks/zod\",\n",
    "        \"winstonjs/winston\",\n",
    "        \"pinojs/pino\",\n",
    "        \"helmetjs/helmet\",\n",
    "        \"moleculerjs/moleculer\",\n",
    "        \"typestack/routing-controllers\",\n",
    "        \"lukeautry/tsoa\",\n",
    "        \"tsedio/tsed\",\n",
    "        \"lobehub/lobe-chat\",\n",
    "        \"vercel/ai\"\n",
    "    ],\n",
    "    \"C# ASP.NET\": [\n",
    "        \"dotnet/aspnetcore\",\n",
    "        \"aspnetrun/run-aspnetcore-microservices\",\n",
    "        \"DapperLib/Dapper\",\n",
    "        \"jasontaylordev/CleanArchitecture\",\n",
    "        \"dotnet/efcore\",\n",
    "        \"App-vNext/Polly\",\n",
    "        \"dotnet/orleans\",\n",
    "        \"HangfireIO/Hangfire\",\n",
    "        \"nopSolutions/nopCommerce\",\n",
    "        \"ThreeMammals/Ocelot\",\n",
    "        \"OrchardCMS/OrchardCore\",\n",
    "        \"dotnetcore/CAP\",\n",
    "        \"gothinkster/aspnetcore-realworld-example-app\"\n",
    "    ],\n",
    "    \"Other\": [\n",
    "        \"karpathy/nn-zero-to-hero\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "total_repos = sum(len(repos) for repos in repositories.values())\n",
    "print(f\"Total repositories to analyze: {total_repos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# GitHub API functions\ndef get_repo_stats(owner, repo, token=None):\n    \"\"\"Fetch repository statistics from GitHub API\"\"\"\n    headers = {}\n    if token:\n        headers['Authorization'] = f'token {token}'\n    \n    repo_url = f'https://api.github.com/repos/{owner}/{repo}'\n    \n    try:\n        response = requests.get(repo_url, headers=headers)\n        \n        if response.status_code == 404:\n            print(f\"‚ö†Ô∏è  Repository {owner}/{repo} not found (404)\")\n            return None\n        elif response.status_code == 403:\n            print(f\"‚ö†Ô∏è  Access denied to {owner}/{repo} (403 - private repo?)\")\n            return None\n        elif response.status_code == 429:\n            print(f\"‚ö†Ô∏è  Rate limit exceeded. Waiting 60 seconds...\")\n            time.sleep(60)\n            return get_repo_stats(owner, repo, token)\n        \n        response.raise_for_status()\n        repo_data = response.json()\n        \n        # Get contributors count\n        contributors_count = get_contributors_count(owner, repo, headers)\n        \n        # Get open pull requests count\n        open_prs_count = get_open_prs_count(owner, repo, headers)\n        \n        return {\n            'repo_path': f'{owner}/{repo}',\n            'stars': repo_data['stargazers_count'],\n            'forks': repo_data['forks_count'],\n            'contributors': contributors_count,\n            'open_issues': repo_data['open_issues_count'],\n            'open_prs': open_prs_count,\n            'created_at': repo_data['created_at'][:10],\n            'pushed_at': repo_data['pushed_at'][:10] if repo_data['pushed_at'] else repo_data['created_at'][:10]\n        }\n        \n    except Exception as e:\n        print(f\"‚ùå Error fetching {owner}/{repo}: {str(e)}\")\n        return None\n\ndef get_contributors_count(owner, repo, headers):\n    \"\"\"Get the number of contributors for a repository\"\"\"\n    try:\n        # GitHub API has a max of 500 contributors returned\n        # For accurate count, we need to check pagination\n        contributors_url = f'https://api.github.com/repos/{owner}/{repo}/contributors?per_page=100&anon=true'\n        response = requests.get(contributors_url, headers=headers)\n        \n        if response.status_code == 200:\n            contributors = response.json()\n            total_count = len(contributors)\n            \n            # Check if there are more pages\n            if 'Link' in response.headers:\n                link_header = response.headers['Link']\n                # Parse the last page number from Link header\n                import re\n                last_page_match = re.search(r'page=(\\d+)>; rel=\"last\"', link_header)\n                if last_page_match:\n                    last_page = int(last_page_match.group(1))\n                    # Get the last page to count remaining contributors\n                    last_page_url = f'{contributors_url}&page={last_page}'\n                    last_response = requests.get(last_page_url, headers=headers)\n                    if last_response.status_code == 200:\n                        last_page_contributors = len(last_response.json())\n                        # Total = (pages - 1) * 100 + last page count\n                        total_count = (last_page - 1) * 100 + last_page_contributors\n            \n            return total_count\n        elif response.status_code == 403:\n            # Repository might have disabled contributor stats\n            return -1\n        else:\n            return -1\n    except Exception as e:\n        print(f\"Error counting contributors for {owner}/{repo}: {str(e)}\")\n        return -1\n\ndef get_open_prs_count(owner, repo, headers):\n    \"\"\"Get the number of open pull requests\"\"\"\n    try:\n        # Use search API for accurate count (it returns total_count directly)\n        search_url = f'https://api.github.com/search/issues?q=is:pr+is:open+repo:{owner}/{repo}'\n        response = requests.get(search_url, headers=headers)\n        \n        if response.status_code == 200:\n            data = response.json()\n            return data.get('total_count', 0)\n        \n        # Fallback to pulls endpoint if search fails\n        prs_url = f'https://api.github.com/repos/{owner}/{repo}/pulls?state=open&per_page=100'\n        response = requests.get(prs_url, headers=headers)\n        \n        if response.status_code == 200:\n            prs = response.json()\n            total_count = len(prs)\n            \n            # Check for pagination\n            if 'Link' in response.headers:\n                link_header = response.headers['Link']\n                import re\n                last_page_match = re.search(r'page=(\\d+)>; rel=\"last\"', link_header)\n                if last_page_match:\n                    last_page = int(last_page_match.group(1))\n                    # Get the last page to count remaining PRs\n                    last_page_url = f'{prs_url}&page={last_page}'\n                    last_response = requests.get(last_page_url, headers=headers)\n                    if last_response.status_code == 200:\n                        last_page_prs = len(last_response.json())\n                        # Total = (pages - 1) * 100 + last page count\n                        total_count = (last_page - 1) * 100 + last_page_prs\n            \n            return total_count\n        else:\n            return -1\n    except Exception as e:\n        print(f\"Error counting PRs for {owner}/{repo}: {str(e)}\")\n        return -1\n\ndef fetch_all_repositories(repositories_dict, token=None):\n    \"\"\"Fetch statistics for all repositories\"\"\"\n    results = []\n    total_repos = sum(len(repos) for repos in repositories_dict.values())\n    current_repo = 0\n    \n    for field, repo_list in repositories_dict.items():\n        print(f\"\\nüîç Processing {field} repositories...\")\n        \n        for repo_path in repo_list:\n            current_repo += 1\n            owner, repo = repo_path.split('/')\n            \n            print(f\"[{current_repo}/{total_repos}] Fetching {repo_path}... \", end=\"\")\n            \n            stats = get_repo_stats(owner, repo, token)\n            if stats:\n                stats['field'] = field\n                results.append(stats)\n                contributors_text = str(stats['contributors']) if stats['contributors'] >= 0 else \"N/A\"\n                prs_text = str(stats['open_prs']) if stats['open_prs'] >= 0 else \"N/A\"\n                print(f\"‚úÖ {stats['stars']} stars, {contributors_text} contributors, {prs_text} PRs\")\n            else:\n                print(\"‚ùå Failed\")\n            \n            time.sleep(0.1)  # Rate limiting\n    \n    return results\n\nprint(\"‚úÖ GitHub API functions defined successfully!\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data\n",
    "github_token = os.environ.get('GITHUB_TOKEN')\n",
    "\n",
    "print(\"üöÄ Starting data collection...\")\n",
    "print(f\"Authentication: {'Enabled' if github_token else 'Disabled (60 requests/hour limit)'}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "start_time = time.time()\n",
    "results = fetch_all_repositories(repositories, github_token)\n",
    "end_time = time.time()\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(f\"‚úÖ Data collection completed!\")\n",
    "print(f\"üìä Successfully collected data for {len(results)} repositories\")\n",
    "print(f\"‚è±Ô∏è  Total time: {end_time - start_time:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "if len(results) > 0:\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Rename columns\n",
    "    df = df.rename(columns={\n",
    "        'repo_path': 'Name',\n",
    "        'field': 'Field',\n",
    "        'stars': 'Stars',\n",
    "        'forks': 'Forks',\n",
    "        'contributors': 'Contributors',\n",
    "        'open_issues': 'Open Issues',\n",
    "        'open_prs': 'Open Pull Requests',\n",
    "        'created_at': 'Date Created',\n",
    "        'pushed_at': 'Last Active'\n",
    "    })\n",
    "    \n",
    "    # Reorder columns\n",
    "    column_order = ['Name', 'Field', 'Stars', 'Forks', 'Contributors', 'Open Issues', 'Open Pull Requests', 'Date Created', 'Last Active']\n",
    "    df = df[column_order]\n",
    "    \n",
    "    # Save with timestamp\n",
    "    csv_filename = 'github_repository_stats.csv'\n",
    "    df.to_csv(csv_filename, index=False)\n",
    "    \n",
    "    # Also save metadata\n",
    "    metadata = {\n",
    "        'last_updated': datetime.now().isoformat(),\n",
    "        'total_repositories': len(df),\n",
    "        'total_stars': int(df['Stars'].sum()),\n",
    "        'collection_time_seconds': round(end_time - start_time, 2)\n",
    "    }\n",
    "    \n",
    "    with open('github_stats_metadata.json', 'w') as f:\n",
    "        json.dump(metadata, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nüíæ Data saved to {csv_filename}\")\n",
    "    print(f\"üìã Metadata saved to github_stats_metadata.json\")\n",
    "    print(f\"\\n‚ú® Now open github_stats_viewer.ipynb to see the results!\")\n",
    "else:\n",
    "    print(\"‚ùå No data collected. Please check your internet connection and GitHub token.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}